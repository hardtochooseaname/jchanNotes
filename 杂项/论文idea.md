# 工程优化

## 知识问答bot

### information gain —— 提升用户多轮对话体验

保留用户会话的历史，记录会话过程中检索并呈现给用户的chunk（可以只保留k次对话内的chunk检索记录，k可以作为一个超参数）

当在给用户当前问题检索chunk时，对chunk的排序会参考之前检索过的chunk

对于最近检索过的chunk、与最近检索过的chunk包含信息相近的块，分数会降低（降低的程度也可以作为一个超参数，通过不断测试得到最佳的值）

目的是尽可能让返回的chunk不是最近刚刚返回过的chunk，或者说要让检索到的知识不是最近刚刚检索过并返回过给用户的（因为这些chunk/知识可能并不是用户希望得到的），要让用户每次的问答都能获得更多更新的知识

#### 具体实现

可以通过互信息来做

在记录的最近返回的chunk列表中，选出几个与本次查询最相关的1个（或k个）chunk，以它为基础，在给检索到的chunk评分时与该chunk互信息越高的，表示其中包含的知识越相近，评分就越低

（或许有更合适的信息论方法）

## 多层级的知识结构


对于教科书这种信息密度很高的文本，可能一块600字的chunk中就会包含很多的知识


如果用总结claim、question、关键词、三元组的方式来tag标记chunk中包含的知识/信息，那么就会增加很多额外和冗余的数据。因为可能原文就是“爱迪生发明了灯泡”，这个原文你总结成claim ”灯泡是爱迪生发明的“，这就是纯在浪费。这时候原文本的一个个句子可能就是很精练的一条条知识了


这时候可以用表格/kv等形式来存放这些密集的知识，而不是一刀切地采用chunk分块的方式（不如直接给提取的实体添加一个chunk来源，可以从实体直接找到chunk，这样可以实现同样的功能，且不需要引入大量额外的与表格相关的工作。如果为存储不同类型信息/知识创造了大量不同的方法，那么可能一是工程上实现很困难，二是效果也不一定好、应对不同文档时的表现差异大、通用性过差，三是真的不够优雅、罗里吧嗦）

## Agentic RAG优化

### 工具调用

- 知识库回答的效果不佳时，调用网络搜索工具来获取补充信息



# 理论优化

### 根据查询的熵自适应调整检索/排序策略

首先对用户查询进行判断，确定用户问题是一个更具体的问题（忽必烈是谁）还是一个更抽象的问题（唐朝有哪些著名的武将）

- 具体问题：倾向在重排序时返回的top-k的chunks的总的熵更低，也就是包含的知识更具体，chunk数量可以少一点
- 非具体问题：倾向在重排序时返回的top-k的chunks的总的熵更高，也就是包含的知识更多样、更难以预测、更随机，chunk数量可以多一点

或者，根据查询的**信息熵**或初步检索到的图节点的**信息量分布**，动态调整图搜索的深度或广度。例如，对于信息熵低的具体查询，进行更深的纵向搜索；对于信息熵高的开放查询，进行更广的横向探索，或者在信息量高的节点附近进行更细致的搜索。

### 基于信息论对实体、关系、三元组打分

在建图阶段，会对每个chunk提取实体、关系和三元组，然后在所有chunk处理完后，把所有的三元组汇总起来然后建图

在最终汇总的知识图谱中，可以基于信息论的概念来对实体和关系打分，用以评估实体和关系的重要性程度

该重要性分数可以用作后续检索阶段的排序/裁剪的依据

### 多跳/推理联系的提取

- KG提取时，额外提取同一个chunk中重要的多跳联系。例如，A和B都是爱迪生的发明、A和B都是C的朋友、A是C的爷爷、C演过A导演的电影
- 为了减少不必要的提取工作，可以只提取与重要实体相关的多跳联系

### 基于信息论优化的MMR算法

当我引入信息论概念后，完全可以用信息论的方法来重写/优化原有的MMR算法，至少可以是一个创新点



---

RAG 系统本身不应该被施加过多的期望，被附加过多的能力

外挂知识库本身不应该过分关心对于某个问题，自己应该如何提供知识、提供哪些知识，才足以回答问题

如何利用知识应该是解决问题的人应该关心的（Agent）



