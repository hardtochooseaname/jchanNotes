# RAG流程

## 三种文档整合方法

### **1. Stuff 方法**

#### 特点

- 将所有文档内容直接拼接成一个字符串，一次性传递给 LLM。
- 简单高效，适合小规模文档集。
- 当文档内容较大时，可能会超出模型的上下文窗口。

#### 对应函数

- **`create_stuff_documents_chain`**

#### 使用场景

- 文档数量少且内容较短，能确保总字符数在模型的上下文窗口内。

#### 工作流程

1. 所有文档被拼接为一个完整的字符串。
2. 拼接后的字符串被填充到 Prompt 的占位符（如 `{context}`）中。
3. LLM 一次性处理所有拼接的文档。

------

### **2. MapReduce 方法**

#### 特点

- **Map 阶段**：将每个文档单独传递给 LLM，并生成初步结果。
- **Reduce 阶段**：将初步结果整合起来，再次传递给 LLM，生成最终结果。
- 分布式处理能力更强，适合大规模文档集。

#### 对应函数

- **`create_map_reduce_documents_chain`**

#### 使用场景

- 文档数量较多或内容较长，无法一次性处理。
- 需要对每个文档进行独立的处理后再整合结果。

#### 工作流程

1. **Map 阶段**：每个文档被单独处理，生成初步答案或摘要。
2. **Reduce 阶段**：将所有初步答案整合为一个输入，再传递给 LLM，生成最终答案。

------

### **3. Refine 方法**

#### 特点

- 逐步改进的方式：
  - 先处理第一份文档，生成初步答案。
  - 后续每一份文档都与当前答案一起传递给 LLM，用于进一步完善答案。
- 适合需要增量改进答案的场景。

#### 对应函数

- **`create_refine_documents_chain`**

#### 使用场景

- 需要逐步引入文档内容，并根据新文档调整和完善答案。
- 答案的准确性和关联性需要不断提高。

#### 工作流程

1. 初始阶段：第一个文档生成初步答案。
2. 后续阶段：每个新文档与当前答案一起传递给 LLM，生成改进后的答案。
3. 最终输出：整合所有文档后生成的完善答案。

------

### **总结**

| 方法          | 对应函数                            | 优势                         | 劣势                     | 适用场景                         |
| ------------- | ----------------------------------- | ---------------------------- | ------------------------ | -------------------------------- |
| **Stuff**     | `create_stuff_documents_chain`      | 简单直接，速度快             | 容易超出上下文窗口       | 小规模文档，内容较短             |
| **MapReduce** | `create_map_reduce_documents_chain` | 支持大规模文档，分布式能力强 | 效率较低，可能丢失上下文 | 大规模文档，需要多步聚合         |
| **Refine**    | `create_refine_documents_chain`     | 增量改进，答案更精确         | 时间复杂度高             | 需要逐步完善答案，文档间强相关性 |

选择哪种方法取决于应用场景的需求和文档内容的规模。你可以根据链的设计和目标动态选择这些方法。