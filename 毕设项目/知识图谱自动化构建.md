# 知识图谱自动化构建

## 核心设计

### 一、基于 LLM 的半开放式动态 Schema 构建策略

> 如何判断某一点知识是节点 or 属性？
>
> 例如，人物A的生日、发表的文章、拥有的某个物品，这三点知识应该是作为属性还是应该是节点，通常有以下几点判断依据：
>
> 1. 是否是固有属性：生日是人物的固有属性，所以一般情况下设置为人物节点的属性。
> 2. 是否会与其他实体产生关联：一般情况下，某个具体的“时间”并不会与其他实体产生关联，但是如果知识图谱是用于关于《中国历史》、《新闻记录》之类的，“时间”会作为关键节点与大量节点产生关联时，就需要把人物生日设置为节点。
> 3. 自身是否有固有属性：如果一个知识/事实其自身也有固有属性，例如”人物发表的文章“，文章可能会有重大影响、核心观点这些属性，那么“文章”就不适合作为人物的属性，而是应该作为单独的节点。

#### 1. 核心设计哲学

- **定义**：一种打破传统预定义僵化本体的模式，允许 Schema 在提取过程中根据数据特征动态生长，但通过严谨的 Prompt 约束（Few-Shot + CoT）来防止类型泛滥。
- **适用场景**：LLM 驱动的自动化知识图谱构建（尤其是针对特定领域如“电子科技史”、“行业报告”等）。
- **目标**：平衡图谱的“结构化规范”与“语义灵活性”，解决冷启动困难和长尾知识丢失的问题。

#### 2. 阶段一：Schema 初始化 (Initialization)

- **触发时机**：用户新建图谱项目，并输入关于该图谱的**“领域/内容描述”**时。
- **基础模板**：系统预置一个 Schema 初始化的 Meta-Prompt 模板，包含两个待填充槽位：
  1. **知识图谱总体概述 (KG Overview)**：定义图谱的边界和用途。
  2. **基础实体类型列表 (Initial Entity List)**：预置最通用的元类型（如 Person, Location, Event）。
- **生成流程**：
  1. 将用户的“内容描述”输入给 LLM。
  2. LLM 基于描述，在基础模板之上，**推断并补充**若干领域特定的基础类型（例如：电子史 -> 补充 Organization, Object, Time）。
  3. 形成一个**“最小可行本体” (Minimum Viable Ontology)** 作为提取的起点。

#### 3. 阶段二：节点 vs. 属性的判别逻辑 (Decision Logic)

在提取过程中，LLM 需要判断一个信息点是作为**独立节点**存在，还是仅作为**属性**依附于其他节点。

- **判别依据（写入 System Prompt）**：
  1. **原子性/固有属性 (Atomicity)**：
     - 如果是简单的值（日期、数字、短语）且无自身描述。
     - *判定*：**属性**。
     - *例*：人物的生日、身高。
  2. **连接性/关联价值 (Connectivity)**：
     - 如果该信息在领域中具有枢纽作用，会连接大量其他实体。
     - *判定*：**节点**。
     - *例*：《中国历史》图谱中的“时间点”（连接大量事件）；《电子史》中的“实验室”（连接多位科学家）。
  3. **自身复杂性 (Self-Complexity)**：
     - 如果该信息本身拥有固有属性（如文章有影响因子、物品有发明时间）。
     - *判定*：**节点**。
     - *例*：人物发表的“文章”、发明的“物品”。

#### 4. 阶段三：Schema 动态演进与控制 (Evolution & Control)

允许在提取过程中发现新类型，但必须严控“Schema 爆炸”和“同义词分裂”。

- **演进机制**：

  - 将当前的实体类型列表动态注入到 Prompt 中。
  - 当 LLM 遇到无法归类的实体时，允许其输出 `Decision: NEW` 并建议新类型。
  - 一旦采纳，更新类型列表，用于后续提取（In-Context Learning）。

- 控制手段：Few-Shot + CoT (关键技术点)

  利用少样本提示（Few-Shot）教导 LLM 归纳标准，并强制要求输出理由（Reasoning）。

  - **样本 1：强行归纳 (Generalization)**
    - *场景*：遇到“晶体管”，现有类型有 `Object`。
    - *逻辑*：虽然不同，但本质是物品，**归入 `Object`**。
    - *目的*：防止为每个零件建一个类型。
  - **样本 2：泛化命名 (Naming Standard)**
    - *场景*：遇到“广义相对论”，现有类型无匹配。
    - *逻辑*：**新建 `Concept`**，而不是新建 `Theory`。
    - *目的*：创建一个高层级的通用类型，涵盖理论、定律、术语。
  - **样本 3：语义断层 (Semantic Gap)**
    - *场景*：遇到“1998年”，现有类型只有人/地/事。
    - *逻辑*：时间是全新维度，无法兼容，**新建 `Time`**。
    - *目的*：仅在本质不同时才扩展 Schema。

#### 5. 系统优势

1. **鲁棒性**：通过 Few-Shot 明确了“归纳”和“新建”的边界，杜绝了相近实体类型（如 Scientist/Researcher）的重复创建。
2. **灵活性**：不需要预先穷举所有类型，能够自适应不同领域的知识提取。
3. **可解释性**：要求 LLM 输出判断理由（Reasoning），便于后续人工审计或调试。

### 二、语义分块

**痛点：** 传统的固定字符数切分（Fixed-size Chunking）容易把一句话截断，或者把同一个知识点的上下文切开，导致实体抽取时关系丢失。 

**解决方案：** **基于结构与语义的双重切分策略。**

- **硬性切分限制（结构感知+chunk长度限制+换行符为界）：** 利用解析工具（如 PyMuPDF 或 Unstructured）识别 PDF 的物理结构（标题、段落、表格）。同时，切分最小单元为段落（段落过长时换行符退化为句号），限制chunk的长度上限。总体实现，1) 绝不跨越“章节标题”进行合并，2）chunk长度不会超过预设限制。
- **语义聚合切分：** 对于章节内的连续文本，使用 Embedding 模型计算相邻段落的**余弦相似度**。设定一个阈值（Threshold）。如果 句子A 和 句子B 的相似度高，说明在讲同一件事，合并；如果相似度突然下降（Break point），说明话题转换了，在此处切分。

**技术优化方案：**

- **滑动窗口（Rolling Window）：** 不要只算 $P_i$ 和 $P_{i+1}$。更稳健的做法是算 $P_i$ 与 $P_{i-1}$ 和 $P_{i+1}$ 的平均相似度，或者维护一个累积的 buffer。

### 三、冲突仲裁机制

**痛点：** 一本书上说 A 是 1990 年生的，另一个文档说 A 是 1991 年生的。 

**解决方案：** **Agentic Verification（代理式核查）。**

- **触发机制：** 当抽取出的三元组与图谱中已有关系产生冲突（例如 `(Person A)-[BORN_IN]->(1990)` vs `(1991)`）时，触发“仲裁 Agent”。
- **执行流程：**
  1. **内部溯源：** Agent 检查两个冲突信息的来源文档权重（教科书 > 课外阅读材料）。
  2. **外部求证：** 如果内部无法决断，调用搜索工具（如 Tavily/Google Search API）联网检索。
  3. **投票决策：** LLM 根据多方信息进行置信度打分，保留高分值，并将冲突记录在边属性 `metadata` 中备查。

### 四、实体对齐与消歧(Entity Resolution / Disambiguation)

**痛点：** “比尔盖茨”、“盖茨”、“Bill Gates” 是同一个人；但不同文档里的“李明”可能是两个人。（同体异名&同名异体） 

**策略：** 提取实体时，额外提取一个 `Claim`（突出特质的简要客观描述）。

**流程：** 查同名（Exact Match）

- 如果有：发起合并操作
- 如何无：发起基于claim的向量查询

**优化方案：**

-  **claim与name混合检索**：块A：“埃隆·马斯克：特斯拉的 CEO”。 块B： “马斯克：SpaceX 的创始人，火星殖民计划推动者”。这两段 `Claim` 的语义相似度可能只有 0.7 左右（因为内容不重叠）。如果你只靠向量检索，可能会**漏掉**合并，导致图谱里出现两个马斯克。

- **模糊区间的LLM二次核查**：当检索到的块其claim与当前块claim的近似度处于一个比较模糊的区间的时候，就会发起基于LLM的二次核查。

