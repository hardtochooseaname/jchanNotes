# PV & PVC

**持久卷（PersistentVolume，PV）** 是集群中的一块存储， 持久卷是集群资源，就像节点也是集群资源一样。PV其实就是对实际存储硬件的抽象，隐藏了存储的具体实现。当集群中的用户需要使用一块存储空间进行持久化存储时，ta使用的其实就是统一抽象的PV。PV可以由管理员事先制备， 或者使用[存储类（Storage Class）](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/)来动态制备。PV 持久卷和普通的 Volume 一样， 也是使用卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。

**持久卷申领（PersistentVolumeClaim，PVC）** 表达的是用户对存储的请求。当需用户需要使用一块存储空间用于持久化存储时，便可以通过描述对于存储的具体需求（PVC），从而在集群中获取满足要求的存储空间（PV）。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 申领会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）。同样 PVC 申领也可以请求特定的大小和访问模式 （例如，可以挂载为 ReadWriteOnce、ReadOnlyMany、ReadWriteMany 或 ReadWriteOncePod， 请参阅[访问模式](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#access-modes)）。



### 结构图

<img src="..\images\image-20240725160422822.png" alt="image-20240725160422822" style="zoom:67%;" />

### 使用

#### 静态制备pv

由运维提前创建好一系列pv供开发人员使用

Pod -> PVC -> PV -> 物理基础设施

----

1. 创建PV卷（运维人员）：提前定义PV，与集群中某个基础设施关联，提供存储空间
2. 创建PVC申领（开发人员/用户）：用户在PVC中描述对存储的需求，master会根据需求在集群中为其匹配合适的PV，并进行**绑定**
3. 创建Pod（开发人员/用户）：Pod在`spec.volumes`中定义PVC类型的卷，并关联到某个PVC

**注意：** 

- PV和PVC都是作为集群的资源而存在。<u>PVC当作存储卷，PV当作物理硬盘/文件系统</u>

- PVC-PV是一对一绑定的关系，该绑定关系具有排他性。当PVC被删除时，PV的处理根据PV回收策略而定

- Pod-PVC则是Pod使用集群中的PVC资源的关系，一个Pod可以使用多个PVC。当pod被删除时，其使用到的PVC不会被影响

  

#### 动态制备pv（StorageClass ）

开发人员通过pvc使用storageClass根据需求动态创建pv

Pod -> PVC -> StorageClass -> PV -> 物理基础设施



### PV的回收策略

当某个PVC不再被需要时（没有任何pod正在使用它），可以选择删除这个PVC，这时与PVC绑定的PV会被**释放**。

PV被如何处理由回收策略`spec.persistentVolumeReclaimPolicy`决定，其取值有两个：

#### 保留（Retain）

回收策略 `Retain` 使得用户可以手动回收资源。当 PersistentVolumeClaim 对象被删除时，PersistentVolume 卷仍然存在，对应的数据卷被视为"已释放（released）"。 由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。 管理员可以通过下面的步骤来手动回收该卷：

1. 删除 PersistentVolume 对象。与之相关的、位于外部基础设施中的存储资产在 PV 删除之后仍然存在。
2. 根据情况，手动清除所关联的存储资产上的数据。
3. 手动删除所关联的存储资产。

如果你希望重用该存储资产，可以基于存储资产的定义创建新的 PersistentVolume 卷对象。

#### 删除（Delete）

对于支持 `Delete` 回收策略的卷插件，删除动作会将 PersistentVolume 对象从 Kubernetes 中移除，同时也会从外部基础设施中移除所关联的存储资产。 动态制备的卷会继承[其 StorageClass 中设置的回收策略](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#reclaim-policy)， 该策略默认为 `Delete`。管理员需要根据用户的期望来配置 StorageClass； 否则 PV 卷被创建之后必须要被编辑或者修补。

---

#### PV的status.phase

- **Available**：PV刚被创建，还未绑定

- **Bounded**：已完成绑定

- **Released**：绑定的PVC被删除（回收策略为Retain时），但是绑定信息会被保留。因此想要重复利用Released状态的PV，就需要把PV的状态改为Available，这可以通过edit编辑PV配置来实现：

  - 删除claimRef字段
  - 把`status.phase`字段改为`Available`

  ```yaml
  # PV的配置文件
  spec:
  ...
    claimRef:	 # PV和PVC通过claimRef实现双向绑定
      apiVersion: v1
      kind: PersistentVolumeClaim
      name: nfs-pvc-test
      namespace: default
      resourceVersion: "611440"
      uid: fa8f33a5-6256-45e2-9154-b6419fe9058d
  ...
  status: # 当前状态
    phase: Released
  ```
  
- **Failed**：绑定的PVC被删除，并且回收策略为Delete时，删除PV的操作失败（可能是硬件/网络故障、权限、插件不支持等问题）

  - NFS: 默认情况下，Kubernetes 不支持删除 NFS 服务器上的数据，因此 `Delete` 策略在 NFS 上无效。你需要手动删除数据或使用自定义的解决方案。

  - AWS EBS: 支持删除。`Delete` 策略会自动删除 EBS 卷。

  - GCE PD: 支持删除。`Delete` 策略会自动删除 GCE 磁盘。

  - Azure Disk: 支持删除。`Delete` 策略会自动删除 Azure 磁盘。

  - Ceph RBD: 支持删除。`Delete` 策略会自动删除 RBD 镜像。

  - Cinder (OpenStack): 支持删除。`Delete` 策略会自动删除 Cinder 卷。



### 访问模式

- `ReadWriteOnce`

  卷可以被一个节点以读写方式挂载。 ReadWriteOnce 访问模式仍然可以在同一节点上运行的多个 Pod 访问该卷。 对于单个 Pod 的访问，请参考 ReadWriteOncePod 访问模式。

- `ReadOnlyMany`

  卷可以被多个节点以只读方式挂载。

- `ReadWriteMany`

  卷可以被多个节点以读写方式挂载。

- `ReadWriteOncePod`

  **特性状态：** `Kubernetes v1.29 [stable]`

  卷可以被单个 Pod 以读写方式挂载。 如果你想确保整个集群中只有一个 Pod 可以读取或写入该 PVC， 请使用 ReadWriteOncePod 访问模式。

在命令行接口（CLI）中，访问模式也使用以下缩写形式：

- RWO - ReadWriteOnce
- ROX - ReadOnlyMany
- RWX - ReadWriteMany
- RWOP - ReadWriteOncePod



## 存储类 - storageClass

>  StorageClass 为管理员提供了描述存储**类**的方法。 不同的类型可能会映射到不同的服务质量等级或备份策略，或是由集群管理员制定的任意策略。 Kubernetes 本身并不清楚各种类代表的什么。

StorageClass 是在 Kubernetes 早期的 PV-PVC 机制基础上引入的，是为了适应存储资源需求的灵活性和自动化管理的要求日益增长的情况。StorageClass 在 Kubernetes 存储系统中的重要性主不仅仅在于动态制备：

##### 1. **简化存储管理**

StorageClass 使得存储资源的管理和使用更加灵活和简便。管理员可以定义不同类型的存储类，以适应不同的应用需求，例如高性能存储、低成本存储和大容量存储。这样，用户在申请存储资源时，只需指定相应的 StorageClass，而不需要关心底层存储的具体实现和配置细节。

##### 2. **支持动态制备**

StorageClass 支持动态制备（dynamic provisioning），这是 Kubernetes 存储系统中的一项重要功能。通过动态制备，用户在创建 PVC 时，Kubernetes 可以根据 StorageClass 的定义自动创建 PV。这减少了管理员的工作负担，因为不再需要手动预先创建 PV。动态制备确保了存储资源的按需分配和自动化管理，提高了资源利用效率。

##### 3. **灵活的存储配置**

通过 StorageClass，管理员可以定义各种存储配置参数，如存储类型（例如 SSD 或 HDD）、复制因子、访问模式、文件系统类型等。这些配置可以直接在 StorageClass 中定义，从而实现了存储资源的灵活配置和优化。

##### 4. **资源隔离和多租户支持**

StorageClass 支持资源隔离和多租户环境。在多租户环境中，不同的用户或应用可以使用不同的 StorageClass，从而实现存储资源的隔离。这有助于保证不同应用之间的性能隔离和数据安全。

##### 5. **存储策略的统一管理**

StorageClass 提供了一个统一的接口和管理机制，用于定义和管理不同的存储策略。通过 StorageClass，管理员可以集中定义和管理各种存储策略，从而简化了存储管理的复杂性。

##### 6. **支持多种存储提供者**

StorageClass 支持多种存储提供者（provisioners），包括云存储（如 AWS EBS、Google Persistent Disk）、分布式存储系统（如 Ceph、GlusterFS）以及传统的网络存储（如 NFS）。这使得 Kubernetes 存储系统具有很高的灵活性和可扩展性，能够适应各种不同的存储需求和环境。

##### 7. **提供存储资源的质量保证**

通过定义不同的 StorageClass，可以为不同的应用提供不同的存储质量保证（QoS）。例如，可以为数据库应用提供高 IOPS 和低延迟的存储，而为日志存储提供大容量和高吞吐量的存储。这样可以根据应用的需求，合理分配和使用存储资源，确保应用的性能和可靠性。



### 实例测试

#### StorageClass配置文件

```yaml
apiVersion: storage.k8s.io/v1  # sc的api组与pv pvc的都不一样，不是v1，这里可以看出来sc是后面新增的特性
kind: StorageClass
metadata:
  name: managed-nfs-storage	 # 名字很重要，PVC通过名字来使用StorageClass配置
  namespace: kube-system
provisioner: fuseim.pri/ifs # 制备器提供者的名字，用于和创建的制备器关联
parameters:
  archiveOnDelete: "false" # 是否存档，false 表示不存档，会删除 oldPath 下面的数据，true 表示存档，会重命名路径
reclaimPolicy: Retain 
volumeBindingMode: Immediate 
```

字段解释：

- `provisioner`：每个 StorageClass 都有一个制备器（Provisioner），用来决定使用哪个卷插件制备 PV。 该字段必须指定。
- `parameters`：StorageClass 的参数描述了存储类的卷。不同的制备器所支持/需要的参数不同，所以这一字段的取值要取决于具体的制备器。 当参数被省略时，会使用默认值。
- `reclaimPolicy`：默认是Delete，可以改为Retain。对于手动创建的PV，如果指定了StorageClass，那么PV的回收策略会自动继承StorageClass的回收策略，不管PV自己配置是啥。
- `volumeBindingMode`：卷绑定模式，控制了[卷绑定和动态制备](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#provisioning)应该发生在什么时候。 当未设置时，默认使用 `Immediate` 模式。
  - `Immediate`，当PVC 被创建时，PV就会被动态制备
  - `WaitForFirstConsumer`：只有使用 PVC 的用户/Pod出现时，PV才会被动态制备（只支持CSI 卷插件和local，前提是特定的 CSI 驱动程序支持此卷）

#### provisioner配置文件

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  namespace: kube-system
  labels:
    app: nfs-client-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: registry.cn-beijing.aliyuncs.com/pylixm/nfs-subdir-external-provisioner:v4.0.0
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME  # 制备器提供者的名字
              value: fuseim.pri/ifs   # 需要和sc的名字一致，这是把sc与制备器关联的关键
            - name: NFS_SERVER
              value: 192.168.18.62  
            - name: NFS_PATH
              value: /data/nfs/rw
      volumes:
        - name: nfs-client-root
          nfs:
            server: 192.168.18.62
            path: /data/nfs/rw
```

#### RBAC权限配置

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  namespace: kube-system
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kube-system
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
```

#### PVC配置文件

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sc-pvc-test
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: "managed-nfs-storage"  # sc的名字
```



### 默认存储类 & 准入控制器

- 当DefaultStorageClass准入控制器被启用，可以设置默认存储类。即所有未设置`storageClassName`的PVC申领，都只能绑定到隶属默认存储类的PV卷
  - 如果没有默认存储类，对PVC的处理与DefaultStorageClass准入控制器被关闭时相同
  - 如果有多个默认存储类，动态制备时使用最新的默认存储类
- 当DefaultStorageClass准入控制器被关闭，不存在默认存储类的说法。那么所有将 `storageClassName` 设为 `""` 的 PVC 只能被绑定到也将 `storageClassName` 设为 `""` 的 PV

**默认存储类通过注解来标记**：`storageclass.kubernetes.io/is-default-class: "true"`

---

由此可见，要实现**静态制备**：

1. 不在集群中设置默认存储类 + `storageClassName`设为空值
2. DefaultStorageClass准入控制器 +  `storageClassName`设为空值

#### 准入控制器

Kubernetes 的准入控制器（Admission Controllers）是一些插件，这些插件在 API 服务器接收到请求并且持久化对象之前对请求进行拦截和处理。这些插件可以执行各种各样的操作，包括验证、修改、拒绝请求等。

> 官方文档：https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/#what-are-they

##### 准入控制器的作用

1. 验证：确保请求符合一定的规则和策略。例如，确保资源配额不被超额使用。
2. 修改：在持久化对象之前对其进行修改。例如，为新建的 Pod 添加特定的标签。
3. 拒绝：拒绝不符合策略的请求。例如，拒绝在特定命名空间内创建资源的请求。

##### 常见的准入控制器插件

以下是一些常见的准入控制器插件：

- NamespaceLifecycle：限制在终止状态的命名空间内创建资源。
- LimitRanger：确保 Pod 和容器的资源请求和限制符合定义的范围。
- ServiceAccount：自动为 Pod 分配 ServiceAccount。
- ResourceQuota：确保命名空间内的资源使用不超过配额限制。
- PodSecurityPolicy：限制 Pod 的安全配置。
- NodeRestriction：限制节点对特定资源的访问。

##### 查看准入控制器启用情况

准入控制器是API server所使用的插件，所以需要查看API server的配置信息：

```sh
cat /etc/kubernetes/manifests/kube-apiserver.yaml

# spec.containers.command字段
- --enable-admission-plugins=NodeRestriction  # 启用的准入控制器插件只有NodeRestriction
```



#### 可追溯的默认 StorageClass 赋值

**特性状态：** `Kubernetes v1.28 [stable]`

你可以创建 PersistentVolumeClaim，而无需为新 PVC 指定 `storageClassName`。 即使你的集群中不存在默认 StorageClass，你也可以这样做。 在这种情况下，新的 PVC 会按照你的定义进行创建，并且在默认值可用之前，该 PVC 的 `storageClassName` 保持不设置。

当一个默认的 StorageClass 变得可用时，控制平面会识别所有未设置 `storageClassName` 的现有 PVC。 对于 `storageClassName` 为空值或没有此主键的 PVC， 控制平面会更新这些 PVC 以设置其 `storageClassName` 与新的默认 StorageClass 匹配。 如果你有一个现有的 PVC，其中 `storageClassName` 是 `""`， 并且你配置了默认 StorageClass，则此 PVC 将不会得到更新。

为了保持绑定到 `storageClassName` 设为 `""` 的 PV（当存在默认 StorageClass 时）， 你需要将关联 PVC 的 `storageClassName` 设置为 `""`。

---

要注意的是，这个新特性和准入控制器插件影响的都是PVC创建`StorageClassName`的赋值。而PV 制备和绑定，都是基于已经确定的 `storageClassName` 进行处理，并不关心`storageClassName`的值是来源于该新特性还是准入控制器插件。



## 示例测试

### 基础版本

- PV使用nfs作为存储
- 静态制备PV

```yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc-test
spec:
  accessModes:
  - ReadOnlyMany
  #volumeMode: Filesystem
  resources:
    requests:
      storage: 2Gi
  storageClassName: ""
  selector: 				# 选择器，过滤备选的PV卷
    matchLabels:
      testing: "true"
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0001
  labels:  				# 标签，可用于PVC对于PV的筛选
    testing: "true"
spec:
  capacity:
    storage: 3Gi
  accessModes:
  - ReadOnlyMany
  #volumeMode: Filesystem # 默认设置，可以省略
  persistentVolumeReclaimPolicy: Delete
  mountOptions: # 挂载选项
    - hard
    - nfsvers=4.1
  nfs:
    path: /data/nfs/rw/test-pv
    server: k8s-node01
  storageClassName: ""  
```



# CSI

### attach & mount

mount是挂载存储卷到容器指定路径，发生在启动docker容器时，也就是Pod启动时。

在这之前需要attach操作，将存储卷挂接到Pod所在节点。

#### attach 挂接

attach为mount挂载做准备工作，实际是将挂载存储卷的一部分前置工作分离出来，提前执行，使得启动Pod时可以更快速地挂载存储卷

attach一个PV卷主要涉及到以下工作：

- **更新PV卷的状态**：标记PV已经被Pod使用，并且挂载到了某个节点（会在两处更新：kubernetes集群、卷插件）
- **创建挂载点：** 在节点上为PV创建一个挂载点，这个挂载点是一个文件系统路径，后续mount操作时会将Volume挂载到这个路径下。
